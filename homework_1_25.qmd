---
title: "Homework 1"
author: "Your Name Here"
format:
  html:
    toc: true
    toc-location: left
    self-contained: true
jupyter: python3
---

Professional wrestling, while not everyone's cup of tea, is big business. What started as a carnival act has turned into a global entertainment industry. Netflix recently started showing Monday Night Raw, a program from the biggest North American wrestling company, WWE -- this deal is reportedly worth \$5 billion. Like any large entity, WWE is not without competition, drama, and scandal. 

## General Tips

This is very much a step-by-step process. Don't go crazy trying to get everything done with as few lines as possible. Read the documentation for the AlphaVantage api! Carefully explore the pages from cagematch. There isn't a need to get too fancy with anything here -- just go with simple function and all should be good. Don't print comments, but use normal text for explanations.

## Step 1

In the `calls` folder, you'll find 4 text files -- these are transcripts from quarterly earnings calls. Read those files in (glob.glob will be very helpful here), with appropriate column names for ticker, quarter, and year columns; this should be done within a single function. Perform any data cleaning that you find necessary. 

```{python}
import glob
import pandas as pd

def read_transcripts(folder_path):
    data = []

    files = glob.glob(f"{folder_path}/*.txt")

    for file in files:
        file_name = file.split("\\")[-1].split("_")  
        ticker = file_name[0]
        quarter = file_name[1]
        year = file_name[2].split(".")[0]

        with open(file, 'r', encoding='utf-8') as f:
            content = f.read()

        data.append({"ticker": ticker, "quarter": quarter, "year": year, "content": content})

    df = pd.DataFrame(data)

    
    df['content'] = df['content'].str.strip()
    df['ticker'] = df['ticker'].str.upper()
    df['quarter'] = df['quarter'].str.upper()
    df['year'] = df['year'].astype(int)

    return df


folder_path = "C:/Users/antfe/OneDrive/Unstructured Analytics/udanotes/calls"

transcripts_df = read_transcripts(folder_path)

print(transcripts_df)  

```

## Step 2

Use the AlphaVantage api to get daily stock prices for WWE and related tickers for the last 5 years -- pay attention to your data. You cannot use any AlphaVantage packages (i.e., you can only use requests to grab the data). Tell me about the general trend that you are seeing. I don't care which viz package you use, but plotly is solid and plotnine is good for ggplot2 users.

```{python}
import requests
import pandas as pd
import plotly.express as px
from datetime import datetime

def fetch_stock_data(symbol, api_key):
    """
    Fetch daily stock price data using TIME_SERIES_DAILY (free-tier Alpha Vantage).
    Args:
        symbol (str): Stock ticker symbol.
        api_key (str): AlphaVantage API key.
    Returns:
        pd.DataFrame: DataFrame with daily stock prices.
    """
    url = f"https://www.alphavantage.co/query"
    params = {
        "function": "TIME_SERIES_DAILY",  
        "symbol": symbol,
        "apikey": api_key,
        "outputsize": "full"  
    }
    
    response = requests.get(url, params=params)
    data = response.json()
    
    if "Time Series (Daily)" not in data:
        print(f"Error fetching data for {symbol}: {data.get('Error Message', 'Unknown error')}")
        return None
    
    daily_prices = data["Time Series (Daily)"]
    df = pd.DataFrame.from_dict(daily_prices, orient="index")
    df = df.reset_index().rename(columns={"index": "date"})
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")
    
    df = df.rename(columns={
        "1. open": "open",
        "2. high": "high",
        "3. low": "low",
        "4. close": "close",
        "5. volume": "volume"
    })
    df = df[["date", "close"]]  
    df["close"] = df["close"].astype(float)
    
    return df

api_key = "CBH71F9YEV11J37I"
tickers = ["TKO", "EDR"]  


stock_data = {}
for ticker in tickers:
    print(f"Fetching data for {ticker}...")
    df = fetch_stock_data(ticker, api_key)
    if df is not None:
        stock_data[ticker] = df.assign(ticker=ticker)


if stock_data:
    combined_data = pd.concat(stock_data.values(), ignore_index=True)
    
    
    five_years_ago = datetime.now() - pd.DateOffset(years=5)
    combined_data = combined_data[combined_data["date"] >= five_years_ago]
    
    fig = px.line(
        combined_data,
        x="date",
        y="close",
        color="ticker",
        title="5-Year Stock Price Trends",
        labels={"close": "Closing Price", "date": "Date"},
    )
    fig.update_layout(xaxis_title="Date", yaxis_title="Closing Price", legend_title="Ticker")
    fig.show()
else:
    print("No valid data fetched. Please check your API key or tickers.")

#In this plot, we can see that the stock prices for both TKO and EDR have been increasing over the past 5 years, but TKO has taken a significant jump while EDR is barely rising. On the AlphaVantage API website, I was not able to pull any WWE data.
```

## Step 3

Just like every other nerdy hobby, professional wrestling draws dedicated fans. Wrestling fans often go to cagematch.net to leave reviews for matches, shows, and wrestlers. The following link contains the top 100 matches on cagematch: https://www.cagematch.net/?id=111&view=statistics

* What is the correlation between WON ratings and cagematch ratings?

** Which wrestler has the most matches in the top 100?

*** Which promotion has the most matches in the top 100? 

**** What is each promotion's average WON rating?

***** Select any single match and get the comments and ratings for that match into a data frame.


```{python}
import requests
from bs4 import BeautifulSoup
import pandas as pd

url = "https://www.cagematch.net/?id=111&view=statistics"

response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')
    
    table_div = soup.find("div", {"class": "Table"})
    
    if table_div:
        rows = table_div.find_all("tr")[1:] 
        
        data = []
        for row in rows:
            columns = row.find_all("td")
            data.append({
                "Rank": columns[0].text.strip(),
                "Date": columns[1].text.strip(),
                "Promotion": columns[2].img["alt"].strip() if columns[2].img else None,
                "Match": columns[3].text.strip(),
                "WON Rating": columns[4].text.strip(),
                "Match Type": columns[5].text.strip(),
                "Rating": columns[6].text.strip(),
                "Votes": columns[7].text.strip()
            })
        
        df = pd.DataFrame(data)
        
        print(df)
```       

```{python}
#* What is the correlation between WON ratings and cagematch ratings?
import re

def convert_won_rating(rating):
    if not isinstance(rating, str):  
        return None
    match = re.match(r"\*{1,5}(?:\*\/\d|\*\d\/\d)?", rating)  
    if match:
        base = rating.count("*")  
        fraction = 0.25 if "1/4" in rating else 0.5 if "1/2" in rating else 0.75 if "3/4" in rating else 0
        return base + fraction
    return None  

df["WON Rating Numeric"] = df["WON Rating"].apply(convert_won_rating)

df_cleaned = df.dropna(subset=["WON Rating Numeric", "Rating"])

correlation = df_cleaned["WON Rating Numeric"].corr(df_cleaned["Rating"])
print(f"Correlation between WON Ratings and Cagematch Ratings: {correlation}")

#Correlation between WON Ratings and Cagematch Ratings: 0.33132540128516674
```

```{python}
#** Which wrestler has the most matches in the top 100?
from collections import Counter

all_wrestlers = []

for match in df["Match"]:
    sides = match.split(" vs. ") if " vs. " in match else [match]
    
    for side in sides:
        wrestlers = side.split(" & ")
        all_wrestlers.extend(wrestlers)

wrestler_counts = Counter(all_wrestlers)

most_common_wrestler = wrestler_counts.most_common(1)[0]
print(f"Wrestler with the most matches: {most_common_wrestler[0]} ({most_common_wrestler[1]} matches)")

# Wrestler with the most matches: Kenny Omega (16 matches)
```

```{python}
#*** Which promotion has the most matches in the top 100? 
promotion_counts = df["Promotion"].value_counts()

top_promotion = promotion_counts.idxmax()
top_promotion_count = promotion_counts.max()

print(f"Top promotion: {top_promotion} with {top_promotion_count} matches")

# Top promotion: New Japan Pro Wrestling with 35 matches
```

```{python}
#**** What is each promotion's average WON rating?
import re

def convert_won_rating(rating):
    if not isinstance(rating, str):  
        return None
    match = re.match(r"\*{1,5}(?:\*\/\d|\*\d\/\d)?", rating)  
    if match:
        base = rating.count("*")  
        fraction = 0.25 if "1/4" in rating else 0.5 if "1/2" in rating else 0.75 if "3/4" in rating else 0
        return base + fraction
    return None  

df["WON Rating"] = df["WON Rating"].apply(convert_won_rating)

print(df["WON Rating"].isna().sum(), "NaN values remain in WON Rating.")

avg_won_ratings = df.groupby("Promotion")["WON Rating"].mean()

print("Average WON Ratings by Promotion:")
print(avg_won_ratings)

#5 NaN values remain in WON Rating.
#Average WON Ratings by Promotion:
#Promotion
#All Elite Wrestling                     5.562500
#All Japan Pro Wrestling                 4.979167
#All Japan Women's Pro-Wrestling         4.916667
#DDT Pro Wrestling                            NaN
#GAEA Japan                                   NaN
#JTO                                     4.750000
#Japanese Women Pro-Wrestling Project    5.000000
#Lucha Underground                            NaN
#New Japan Pro Wrestling                 5.392857
#Pro Wrestling NOAH                      4.785714
#Ring Of Honor                           4.928571
#Total Nonstop Action Wrestling          5.000000
#World Championship Wrestling            5.000000
#World Wonder Ring Stardom               5.500000
#World Wrestling Entertainment           4.892857
```

```{python}
#***** Select any single match and get the comments and ratings for that match into a data frame.

import requests
from bs4 import BeautifulSoup
import pandas as pd

url = "https://www.cagematch.net/?id=111&nr=8034&page=99"
response = requests.get(url)

soup = BeautifulSoup(response.content, "html.parser")

comments_section = soup.find_all("div", class_="Comment")

comments_data = []

for comment in comments_section:
    commenter = comment.find("a")  
    comment_text = comment.find("div", class_="CommentContents")  
    if commenter and comment_text:
        commenter_name = commenter.get_text(strip=True)
        comment_content = comment_text.get_text(strip=True)
        
        rating = comment.find("span", class_="Rating")  
        if rating:
            rating_value = rating.get_text(strip=True)
        else:
            rating_value = "No rating"

        comments_data.append({
            "Commenter": commenter_name,
            "Rating": rating_value,
            "Comment": comment_content
        })

df_comments = pd.DataFrame(comments_data)

print(df_comments)


```

## Step 4

You can't have matches without wrestlers. The following link contains the top 100 wrestlers, according to cagematch: https://www.cagematch.net/?id=2&view=statistics

*** Of the top 100, who has wrestled the most matches?

***** Of the top 100, which wrestler has the best win/loss?

```{python}
import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_wrestler_links():
    """
    Scrapes the top 100 wrestlers' names and profile links from the main page.
    
    Returns:
        pd.DataFrame: A DataFrame containing wrestler names and profile links.
    """
    url = "https://www.cagematch.net/?id=2&view=statistics"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    
    if response.status_code != 200:
        print("Failed to fetch the main page.")
        return pd.DataFrame()

    # Parse the page
    soup = BeautifulSoup(response.content, "html.parser")
    table = soup.find("table", class_="TBase TableBorderColor")  # Updated class name
    if not table:
        print("Table not found!")
        return pd.DataFrame()

    rows = table.find_all("tr", class_=["TRow1", "TRow2"])  # Rows with data

    data = []
    for row in rows:
        cols = row.find_all("td")
        if len(cols) > 1:  # Ensure the row contains data
            name_tag = cols[1].find("a")  # Link to wrestler's profile
            if name_tag:
                name = name_tag.text.strip()
                link = "https://www.cagematch.net/" + name_tag["href"]
                data.append({"Wrestler": name, "Profile Link": link})

    return pd.DataFrame(data)

# Scrape wrestler links
wrestler_links_df = scrape_wrestler_links()
print(wrestler_links_df.head())

```

## Step 5

With all of this work out of the way, we can start getting down to strategy.

First, what talent should WWE pursue? Advise carefully.

Second, reconcile what you found in steps 3 and 4 with Netflix's relationship with WWE. Use the data from the following page to help make your case: https://wrestlenomics.com/tv-ratings/

Third, do you have any further recommendations for WWE?